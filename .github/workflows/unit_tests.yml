name: 'Unit tests'

on:
  pull_request:
    branches:
      - main
      - develop
jobs:
    tests:
        name: 'Execute unit tests'
        runs-on: ubuntu-22.04
        defaults:
          run:
            shell: bash
        steps:
        - name: Checkout
          uses: actions/checkout@v3
        - name: Set up Python
          uses: actions/setup-python@v5
          with:
            python-version: "3.12.8"
        - name: Setup Java
          uses: actions/setup-java@v2
          with:
            distribution: 'microsoft'
            java-version: '17.0.1'
        - name: Install requirements
          run: | 
            pip install -r src/requirements.txt
            pip install pytest==8.3.3
            pip install pytest-timeout==2.3.1
    
            # Fix host file to avoid issues with Spark
            echo "127.0.0.1 localhost" | sudo tee /etc/hosts
            echo "::1 localhost ip6-localhost ip6-loopback" | sudo tee -a /etc/hosts
            echo "fe00::0 ip6-localnet" | sudo tee -a /etc/hosts
            echo "ff00::0 ip6-mcastprefix" | sudo tee -a /etc/hosts
            echo "ff02::1 ip6-allnodes" | sudo tee -a /etc/hosts
            echo "ff02::2 ip6-allrouters" | sudo tee -a /etc/hosts
            echo "ff02::3 ip6-allhosts" | sudo tee -a /etc/hosts
            echo "127.0.0.1 $(hostname)" | sudo tee -a /etc/hosts
        - name: Run MySQL container
          run: | 
            docker run --name ploosh_mysql \
              -e MYSQL_ROOT_PASSWORD="${{ secrets.TEST_LOCAL_DB_PASSWORD }}" \
              -e MYSQL_PASSWORD="${{ secrets.TEST_LOCAL_DB_PASSWORD }}" \
              -e MYSQL_DATABASE=ploosh \
              -e MYSQL_USER=ploosh \
              -p 3306:3306 \
              -d mysql
        - name: Run PostgreSQL container
          run: | 
            docker run --name ploosh_postgresql \
              -e POSTGRES_USER=ploosh \
              -e POSTGRES_PASSWORD="${{ secrets.TEST_LOCAL_DB_PASSWORD }}" \
              -e POSTGRES_DB=ploosh \
              -p 5432:5432 \
              -d postgres
        - name: Run SQL Server container
          run: | 
            docker run --name ploosh_mssql \
              -e ACCEPT_EULA="Y" \
              -e MSSQL_SA_PASSWORD="${{ secrets.TEST_LOCAL_DB_PASSWORD }}" \
              --hostname ploosh \
              -p 1433:1433 \
              -d \
              mcr.microsoft.com/mssql/server:2022-latest

        - name: Run Spark master container
          run: | 
            docker run -d --name ploosh-spark-master \
              -e SPARK_MODE=master \
              -e SPARK_MASTER_HOST=ploosh-spark-master \
              -p 7077:7077 -p 8081:8080 \
              -v $(pwd)/tests/.data:$(pwd)/tests/.data \
              -v $(pwd)/tests/.env:$(pwd)/tests/.env \
              --hostname ploosh-spark-master \
              bitnami/spark

            docker exec ploosh-spark-master pip install delta-spark==3.3.0
        - name: Run Spark worker container
          run: |         
            docker run -d --name ploosh-spark-worker \
              -e SPARK_MODE=worker \
              -e SPARK_MASTER_URL=spark://ploosh-spark-master:7077 \
              -e SPARK_WORKER_MEMORY=2g \
              -e SPARK_WORKER_CORES=1 \
              -v $(pwd)/tests/.data:$(pwd)/tests/.data \
              -v $(pwd)/tests/.env:$(pwd)/tests/.env \
              --link ploosh-spark-master:ploosh-spark-master \
              bitnami/spark
    
              docker exec ploosh-spark-worker pip install delta-spark==3.3.0
        - name: Feed databases
          run: | 
            sleep 30 # wait until all services are up
            
            mysql -h 127.0.0.1 -u ploosh -p'${{ secrets.TEST_LOCAL_DB_PASSWORD }}' < tests/.env/mysql/setup.sql
    
            export PGPASSWORD='${{ secrets.TEST_LOCAL_DB_PASSWORD }}';
            psql -h 127.0.0.1 -U ploosh -d ploosh -f tests/.env/postgresql/setup.sql
    
            /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P "${{ secrets.TEST_LOCAL_DB_PASSWORD }}" -i tests/.env/mssql/setup.sql
    
            spark_setup_file=$(pwd)/tests/.env/spark/setup.sql
            spark_setup_file_tmp=$(pwd)/tests/.env/spark/setup_tmp.sql
            sed "s|{{pwd}}|$(pwd)|g" $spark_setup_file > $spark_setup_file_tmp
            spark-sql -f$spark_setup_file_tmp
        - name: Execute tests
          run: | 
            export TEST_DB_PASSWORD="${{ secrets.TEST_LOCAL_DB_PASSWORD }}"
            pytest -rA ./tests 
    